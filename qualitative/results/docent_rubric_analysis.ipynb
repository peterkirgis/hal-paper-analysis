{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docent import Docent\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "DOCENT_API_KEY = os.getenv(\"DOCENT_API_KEY\")\n",
    "\n",
    "client = Docent(\n",
    "    api_key=DOCENT_API_KEY,\n",
    ")\n",
    "\n",
    "collections = client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e7780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'b64b3811-7210-46f1-84fb-c97693ac4f56',\n",
       "  'name': 'scicode_scicode_tool_calling_agent_all_tasks',\n",
       "  'description': 'HAL paper analysis: scicode_scicode_tool_calling_agent_all_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-15T21:20:29.554919'},\n",
       " {'id': '02879d7f-5e50-4bca-8dd7-33a39da4762d',\n",
       "  'name': 'assistantbench_assistantbench_browser_agent_all_tasks',\n",
       "  'description': 'HAL paper analysis: assistantbench_assistantbench_browser_agent_all_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-14T20:02:41.987507'},\n",
       " {'id': 'e80ca13a-028c-4cc8-9ea5-1977aa04297d',\n",
       "  'name': 'taubench_airline_taubench_fewshot_all_tasks',\n",
       "  'description': 'HAL paper analysis: taubench_airline_taubench_fewshot_all_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-14T19:16:56.519991'},\n",
       " {'id': 'db38b00b-3097-4e63-abc6-b36a7c58a7e8',\n",
       "  'name': 'corebench_hard_coreagent_all_tasks',\n",
       "  'description': 'HAL paper analysis: corebench_hard_coreagent_all_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-14T16:47:03.275682'},\n",
       " {'id': 'ada74004-ae2b-418d-be0f-87477d546806',\n",
       "  'name': 'assistantbench_assistantbench_browser_agent_all_tasks',\n",
       "  'description': 'HAL paper analysis: assistantbench_assistantbench_browser_agent_all_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-07T04:47:47.181061'},\n",
       " {'id': '2e3d922a-ff0d-4306-9ba3-699ff7bf92de',\n",
       "  'name': 'scicode_scicode_tool_calling_agent_10_tasks',\n",
       "  'description': 'HAL paper analysis: scicode_scicode_tool_calling_agent_10_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-04T20:05:10.719232'},\n",
       " {'id': 'c39d2945-aa81-4cdc-9270-3cf634e8a2f4',\n",
       "  'name': 'corebench_hard_coreagent_10_tasks',\n",
       "  'description': 'HAL paper analysis: corebench_hard_coreagent_10_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-04T19:07:05.046620'},\n",
       " {'id': '0df5be24-b09a-40ff-9ec7-c35b5a66841d',\n",
       "  'name': 'assistantbench_assistantbench_browser_agent_10_tasks',\n",
       "  'description': 'HAL paper analysis: assistantbench_assistantbench_browser_agent_10_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-04T17:59:31.249386'},\n",
       " {'id': 'f7bfc655-a05b-4cdb-ad5e-315bcd232a51',\n",
       "  'name': 'taubench_airline_taubench_fewshot_10_tasks',\n",
       "  'description': 'HAL paper analysis: taubench_airline_taubench_fewshot_10_tasks',\n",
       "  'created_by': 'b684fd99-8fa8-4134-9699-9b6cde426cb7',\n",
       "  'created_at': '2025-09-04T16:47:32.931837'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e786f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_id = \"b64b3811-7210-46f1-84fb-c97693ac4f56\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86707fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubrics = client.list_rubrics(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d4bec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '83762c94-012f-4648-bec5-5a6f24582f03',\n",
       "  'version': 3,\n",
       "  'rubric_text': 'Instruction Violation: SciCode is evaluated by running the final cell of the agent output against a set of unit tests. As a result, the test will automatically fail if there are any syntax errors or text in the final cell. Is the final cell in the log something other than correctly formatted Python code?\\n\\nLabel as a match all runs with a Python syntax error in the final cell which would trigger an error if the full cell was run in a Python interpreter. Label as no match all other runs.',\n",
       "  'judge_model': {'provider': 'openai',\n",
       "   'model_name': 'gpt-5',\n",
       "   'reasoning_effort': 'medium'},\n",
       "  'output_schema': {'type': 'object',\n",
       "   'properties': {'label': {'enum': ['match', 'no match'], 'type': 'string'},\n",
       "    'explanation': {'type': 'string', 'citations': True}}}},\n",
       " {'id': 'e9d7dd28-2454-41d5-b493-7c8e9ed431c0',\n",
       "  'version': 3,\n",
       "  'rubric_text': 'Tool use: The agent scaffold in SciCode gives the agent access to wikipedia and a python interpreter where it can run test functions. Did the agent fail to use one of these tools properly?\\n\\nLabel as a match all runs where the agent has at least one tool calling error. Label as no match all runs where there are no tool calling errors.',\n",
       "  'judge_model': {'provider': 'openai',\n",
       "   'model_name': 'gpt-5',\n",
       "   'reasoning_effort': 'medium'},\n",
       "  'output_schema': {'type': 'object',\n",
       "   'properties': {'label': {'enum': ['match', 'no match'], 'type': 'string'},\n",
       "    'explanation': {'type': 'string', 'citations': True}}}},\n",
       " {'id': '82b30d80-cab4-4ee3-a9bc-24793745228e',\n",
       "  'version': 3,\n",
       "  'rubric_text': 'Verification: The SciCode benchmark asks AI agents to build complex python functions to model scientific domains. One of the main ways an agent could improve on this task is by constructing verifiers that are correlated with the verifiers in the benchmark. Did the agent construct and pass an intermediate verifier?\\n\\nMark as a match any runs where the agent successfully constructs and passes at least one self-constructed unit test. Mark as no match all runs where the agent does not construct any unit tests or is unable to pass any of them.',\n",
       "  'judge_model': {'provider': 'openai',\n",
       "   'model_name': 'gpt-5',\n",
       "   'reasoning_effort': 'medium'},\n",
       "  'output_schema': {'type': 'object',\n",
       "   'properties': {'label': {'enum': ['match', 'no match'], 'type': 'string'},\n",
       "    'explanation': {'type': 'string', 'citations': True}}}},\n",
       " {'id': 'c27fac3a-01e1-4241-9348-8fa197592d3b',\n",
       "  'version': 2,\n",
       "  'rubric_text': 'Self-Correction: Did the agent successfully correct a previous attempt at testing a solution, either due to fixing an import error or fixing an assertion error in the unit test it constructed?\\n\\nMark as a match all runs where the agent successfully corrects a previously failed unit test or self-corrects a tool calling failure on a second attempt. Mark as no match all other runs.',\n",
       "  'judge_model': {'provider': 'openai',\n",
       "   'model_name': 'gpt-5',\n",
       "   'reasoning_effort': 'medium'},\n",
       "  'output_schema': {'type': 'object',\n",
       "   'properties': {'label': {'enum': ['match', 'no match'], 'type': 'string'},\n",
       "    'explanation': {'type': 'string', 'citations': True}}}},\n",
       " {'id': '31002fcf-8750-4615-9cdd-28206aad0636',\n",
       "  'version': 2,\n",
       "  'rubric_text': 'Environmental Barrier: Did the agent encounter a barrier in the agent scaffold or the environment that prevented it from completing the task, such as a necessary package it was unable to import?\\n\\nMark as a match any runs where an environmental barrier prevents the agent from accessing a tool properly, such as an unavailable import that is necessary for implementing the function it will be tested on. Mark as no match all other runs.',\n",
       "  'judge_model': {'provider': 'openai',\n",
       "   'model_name': 'gpt-5',\n",
       "   'reasoning_effort': 'medium'},\n",
       "  'output_schema': {'type': 'object',\n",
       "   'properties': {'label': {'enum': ['match', 'no match'], 'type': 'string'},\n",
       "    'explanation': {'type': 'string', 'citations': True}}}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rubrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rubric_id = \"31002fcf-8750-4615-9cdd-28206aad0636\"\n",
    "run_state = client.get_rubric_run_state(collection_id, rubric_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cpmhiuh5up4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 616 runs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 616/616 [02:45<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created DataFrame with 616 rows and 19 columns\n",
      "ðŸ“Š Columns: ['agent_run_id', 'benchmark_id', 'model', 'task_id', 'weave_task_id', 'reasoning_effort', 'eval_is_successful', 'original_message_count', 'docent_message_count', 'failed_message_count', 'run_id', 'eval_failed_tasks_count', 'eval_successful_tasks_count', 'eval_successful_tasks', 'eval_successful_subtasks', 'eval_has_successful_subtasks', 'transcript_id', 'transcript_created_at', 'transcript_message_count']\n",
      "ðŸ“Š Successful runs: 25\n",
      "ðŸ“Š Models: {'openai/o4-mini-2025-04-16_low': 62, 'openai/gemini-2.0-flash': 61, 'gpt-4.1-2025-04-14': 60, 'openai/o4-mini-2025-04-16_high': 60, 'openai/claude-3-7-sonnet-20250219_high': 58, 'openai/claude-3-7-sonnet-20250219': 58, 'openai/o3-2025-04-16': 58, 'openai/gpt-5': 57, 'openai/deepseek-ai/DeepSeek-V3': 55, 'openrouter/anthropic/claude-opus-4.1': 45, 'openai/deepseek-ai/DeepSeek-R1': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "agent_run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "benchmark_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "task_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weave_task_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reasoning_effort",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "eval_is_successful",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "original_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "docent_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "failed_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_failed_tasks_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_successful_tasks_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_successful_tasks",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_successful_subtasks",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_has_successful_subtasks",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "transcript_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "transcript_created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "transcript_message_count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2eeb62af-26a6-47e9-9b45-9b364e47f7e8",
       "rows": [
        [
         "0",
         "c99750eb-391c-4416-af0e-37e1d88c3249",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "27",
         "27",
         "high",
         "False",
         "85",
         "85",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "[]",
         "False",
         "1bf5f9a9-c7dd-4b64-b9c1-8331684187cb",
         "2025-09-15 21:20:46.883184",
         "85"
        ],
        [
         "1",
         "193fa9e6-f306-4884-aacc-f8b46b451af9",
         "scicode",
         "openai/claude-3-7-sonnet-20250219",
         "35",
         "35",
         null,
         "False",
         "88",
         "88",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_1745294865_UPLOAD.zip",
         "63",
         "2",
         "['74', '36']",
         "['35.1']",
         "True",
         "3108978d-b4db-4632-9a95-c93ddd3c2f69",
         "2025-09-15 21:20:37.011008",
         "88"
        ],
        [
         "2",
         "9d7383f6-e278-4fb9-aeb2-3620cc1b13b7",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "35",
         "35",
         "high",
         "False",
         "85",
         "85",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "[]",
         "False",
         "b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3",
         "2025-09-15 21:20:46.883193",
         "85"
        ],
        [
         "3",
         "9ebb1c86-9296-47ec-9386-8d4897ae28ba",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "15",
         "15",
         "high",
         "False",
         "58",
         "58",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "['15.1']",
         "True",
         "0d5487f6-f4da-4d09-8065-ffb0b42f5a2c",
         "2025-09-15 21:20:46.883170",
         "58"
        ],
        [
         "4",
         "2223fd62-676e-46af-867e-6f19d7f5df10",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "31",
         "31",
         "high",
         "False",
         "84",
         "84",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "['31.1']",
         "True",
         "bc0819d1-388b-44f9-bc7f-6b840e95eae2",
         "2025-09-15 21:20:46.883188",
         "84"
        ]
       ],
       "shape": {
        "columns": 19,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent_run_id</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>model</th>\n",
       "      <th>task_id</th>\n",
       "      <th>weave_task_id</th>\n",
       "      <th>reasoning_effort</th>\n",
       "      <th>eval_is_successful</th>\n",
       "      <th>original_message_count</th>\n",
       "      <th>docent_message_count</th>\n",
       "      <th>failed_message_count</th>\n",
       "      <th>run_id</th>\n",
       "      <th>eval_failed_tasks_count</th>\n",
       "      <th>eval_successful_tasks_count</th>\n",
       "      <th>eval_successful_tasks</th>\n",
       "      <th>eval_successful_subtasks</th>\n",
       "      <th>eval_has_successful_subtasks</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_created_at</th>\n",
       "      <th>transcript_message_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c99750eb-391c-4416-af0e-37e1d88c3249</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>scicode_scicode_tool_calling_agent_claude37son...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1bf5f9a9-c7dd-4b64-b9c1-8331684187cb</td>\n",
       "      <td>2025-09-15 21:20:46.883184</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>193fa9e6-f306-4884-aacc-f8b46b451af9</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>scicode_scicode_tool_calling_agent_claude37son...</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>['74', '36']</td>\n",
       "      <td>['35.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>3108978d-b4db-4632-9a95-c93ddd3c2f69</td>\n",
       "      <td>2025-09-15 21:20:37.011008</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9d7383f6-e278-4fb9-aeb2-3620cc1b13b7</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>scicode_scicode_tool_calling_agent_claude37son...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3</td>\n",
       "      <td>2025-09-15 21:20:46.883193</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9ebb1c86-9296-47ec-9386-8d4897ae28ba</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>scicode_scicode_tool_calling_agent_claude37son...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>['15.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>0d5487f6-f4da-4d09-8065-ffb0b42f5a2c</td>\n",
       "      <td>2025-09-15 21:20:46.883170</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2223fd62-676e-46af-867e-6f19d7f5df10</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>high</td>\n",
       "      <td>False</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>scicode_scicode_tool_calling_agent_claude37son...</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>['31.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>bc0819d1-388b-44f9-bc7f-6b840e95eae2</td>\n",
       "      <td>2025-09-15 21:20:46.883188</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           agent_run_id benchmark_id  \\\n",
       "0  c99750eb-391c-4416-af0e-37e1d88c3249      scicode   \n",
       "1  193fa9e6-f306-4884-aacc-f8b46b451af9      scicode   \n",
       "2  9d7383f6-e278-4fb9-aeb2-3620cc1b13b7      scicode   \n",
       "3  9ebb1c86-9296-47ec-9386-8d4897ae28ba      scicode   \n",
       "4  2223fd62-676e-46af-867e-6f19d7f5df10      scicode   \n",
       "\n",
       "                                    model task_id weave_task_id  \\\n",
       "0  openai/claude-3-7-sonnet-20250219_high      27            27   \n",
       "1       openai/claude-3-7-sonnet-20250219      35            35   \n",
       "2  openai/claude-3-7-sonnet-20250219_high      35            35   \n",
       "3  openai/claude-3-7-sonnet-20250219_high      15            15   \n",
       "4  openai/claude-3-7-sonnet-20250219_high      31            31   \n",
       "\n",
       "  reasoning_effort  eval_is_successful  original_message_count  \\\n",
       "0             high               False                      85   \n",
       "1             None               False                      88   \n",
       "2             high               False                      85   \n",
       "3             high               False                      58   \n",
       "4             high               False                      84   \n",
       "\n",
       "   docent_message_count  failed_message_count  \\\n",
       "0                    85                     0   \n",
       "1                    88                     0   \n",
       "2                    85                     0   \n",
       "3                    58                     0   \n",
       "4                    84                     0   \n",
       "\n",
       "                                              run_id  eval_failed_tasks_count  \\\n",
       "0  scicode_scicode_tool_calling_agent_claude37son...                       62   \n",
       "1  scicode_scicode_tool_calling_agent_claude37son...                       63   \n",
       "2  scicode_scicode_tool_calling_agent_claude37son...                       62   \n",
       "3  scicode_scicode_tool_calling_agent_claude37son...                       62   \n",
       "4  scicode_scicode_tool_calling_agent_claude37son...                       62   \n",
       "\n",
       "   eval_successful_tasks_count eval_successful_tasks eval_successful_subtasks  \\\n",
       "0                            3    ['74', '25', '30']                       []   \n",
       "1                            2          ['74', '36']                 ['35.1']   \n",
       "2                            3    ['74', '25', '30']                       []   \n",
       "3                            3    ['74', '25', '30']                 ['15.1']   \n",
       "4                            3    ['74', '25', '30']                 ['31.1']   \n",
       "\n",
       "   eval_has_successful_subtasks                         transcript_id  \\\n",
       "0                         False  1bf5f9a9-c7dd-4b64-b9c1-8331684187cb   \n",
       "1                          True  3108978d-b4db-4632-9a95-c93ddd3c2f69   \n",
       "2                         False  b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3   \n",
       "3                          True  0d5487f6-f4da-4d09-8065-ffb0b42f5a2c   \n",
       "4                          True  bc0819d1-388b-44f9-bc7f-6b840e95eae2   \n",
       "\n",
       "       transcript_created_at  transcript_message_count  \n",
       "0 2025-09-15 21:20:46.883184                        85  \n",
       "1 2025-09-15 21:20:37.011008                        88  \n",
       "2 2025-09-15 21:20:46.883193                        85  \n",
       "3 2025-09-15 21:20:46.883170                        58  \n",
       "4 2025-09-15 21:20:46.883188                        84  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_state_df = pd.DataFrame(run_state['results'])\n",
    "\n",
    "# Collect all run data and metadata\n",
    "run_data = []\n",
    "\n",
    "print(f\"Processing {len(run_state['results'])} runs...\")\n",
    "\n",
    "for run in tqdm(run_state['results']):\n",
    "    run_id = run.get('agent_run_id')\n",
    "    \n",
    "    try:\n",
    "        # Get the run info from docent\n",
    "        run_info = client.get_agent_run(collection_id, run_id)\n",
    "        metadata = run_info.metadata\n",
    "        \n",
    "        # Extract basic run info\n",
    "        row_data = {\n",
    "            'agent_run_id': run_id,\n",
    "            'benchmark_id': metadata.get('benchmark_id'),\n",
    "            'model': metadata.get('model'),\n",
    "            'task_id': metadata.get('task_id'),\n",
    "            'weave_task_id': metadata.get('weave_task_id'),\n",
    "            'reasoning_effort': metadata.get('reasoning_effort'),\n",
    "            'eval_is_successful': metadata.get('eval_is_successful'),\n",
    "            'original_message_count': metadata.get('original_message_count'),\n",
    "            'docent_message_count': metadata.get('docent_message_count'),\n",
    "            'failed_message_count': metadata.get('failed_message_count'),\n",
    "        }\n",
    "        \n",
    "        # Add all other metadata fields with prefix\n",
    "        for key, value in metadata.items():\n",
    "            if key not in row_data:  # Don't duplicate already extracted fields\n",
    "                # Handle lists/arrays by converting to string or counting\n",
    "                if isinstance(value, list):\n",
    "                    if key.endswith('_tasks'):\n",
    "                        row_data[f\"{key}_count\"] = len(value)\n",
    "                        # Only store first few items to avoid huge cells\n",
    "                        if len(value) <= 5:\n",
    "                            row_data[key] = str(value)\n",
    "                    else:\n",
    "                        row_data[key] = str(value)\n",
    "                else:\n",
    "                    row_data[key] = value\n",
    "        \n",
    "        # Add transcript info - handle both list and dict formats\n",
    "        if run_info.transcripts:\n",
    "            if isinstance(run_info.transcripts, dict):\n",
    "                # Dictionary format - look for 'default' key\n",
    "                if 'default' in run_info.transcripts:\n",
    "                    transcript = run_info.transcripts['default']\n",
    "                    row_data['transcript_id'] = transcript.id\n",
    "                    row_data['transcript_created_at'] = transcript.created_at\n",
    "                    row_data['transcript_message_count'] = len(transcript.messages)\n",
    "            elif isinstance(run_info.transcripts, list) and len(run_info.transcripts) > 0:\n",
    "                # List format - take the first transcript\n",
    "                transcript = run_info.transcripts[0]\n",
    "                row_data['transcript_id'] = transcript.id\n",
    "                row_data['transcript_created_at'] = transcript.created_at\n",
    "                row_data['transcript_message_count'] = len(transcript.messages)\n",
    "        \n",
    "        run_data.append(row_data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing run {run_id}: {e}\")\n",
    "        # Add error row with basic info\n",
    "        run_data.append({\n",
    "            'agent_run_id': run_id,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(run_data)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# join run_state_df with run_data\n",
    "merged_df = pd.merge(run_state_df, df, on='agent_run_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87006eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (616, 25)\n",
      "Filtered & expanded shape: (616, 28)\n",
      "Rows with 'no match' removed: 0\n",
      "\n",
      "New columns from output expansion:\n",
      "['output_label', 'output_explanation.text', 'output_explanation.citations']\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "agent_run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rubric_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rubric_version",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "value",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "result_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "benchmark_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "task_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weave_task_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reasoning_effort",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "eval_is_successful",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "original_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "docent_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "failed_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_failed_tasks_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_successful_tasks_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_successful_tasks",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_successful_subtasks",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eval_has_successful_subtasks",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "transcript_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "transcript_created_at",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "transcript_message_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_explanation.text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "output_explanation.citations",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "acf5a0e2-3523-497b-8a33-d9ec277ab510",
       "rows": [
        [
         "0",
         "4b3c7a80-4033-4ea1-8da8-70eeb1769d02",
         "c99750eb-391c-4416-af0e-37e1d88c3249",
         "31002fcf-8750-4615-9cdd-28206aad0636",
         "2",
         null,
         "direct_result",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "27",
         "27",
         "high",
         "False",
         "85",
         "85",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "[]",
         "False",
         "1bf5f9a9-c7dd-4b64-b9c1-8331684187cb",
         "2025-09-15 21:20:46.883184",
         "85",
         "match",
         "match",
         "The agent encountered an environmental barrier when attempting to use the web_search tool, receiving a DuckDuckGo rate limit error that prevented access to the search results T0B7. This qualifies as an environmental/tool-access barrier under the rubric.",
         "[{'start_idx': 175, 'end_idx': 179, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 7, 'action_unit_idx': None, 'start_pattern': \"Code execution failed at line 'result = web_search(query=search_query)' due to: DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ 202 Ratelimit\"}]"
        ],
        [
         "1",
         "d83409ad-a78b-473d-9c0a-96188bcc3fd1",
         "193fa9e6-f306-4884-aacc-f8b46b451af9",
         "31002fcf-8750-4615-9cdd-28206aad0636",
         "2",
         null,
         "direct_result",
         "scicode",
         "openai/claude-3-7-sonnet-20250219",
         "35",
         "35",
         null,
         "False",
         "88",
         "88",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_1745294865_UPLOAD.zip",
         "63",
         "2",
         "['74', '36']",
         "['35.1']",
         "True",
         "3108978d-b4db-4632-9a95-c93ddd3c2f69",
         "2025-09-15 21:20:37.011008",
         "88",
         "no match",
         "no match",
         "The agent did encounter an environmental restriction when attempting to import a disallowed module (heapq), as indicated by the error stating that the import is not allowed and listing the authorized imports T0B36. However, this did not prevent task completion: the agent adapted by rewriting the function to use only the allowed dependencies (numpy and itertools) and proceeded with a brute-force approach without heapq T0B38. Since the environmental barrier was circumvented and did not block access to necessary tools or the ability to provide the required implementation, it does not meet the rubricâ€™s threshold of preventing task completion.",
         "[{'start_idx': 208, 'end_idx': 213, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 36, 'action_unit_idx': None, 'start_pattern': \"Code execution failed at line 'import heapq' due to: InterpreterError: Import of heapq is not allowed. Authorized imports are: ['math', 'collections', 'copy', 'time', 're', 'unicodedata', 'functools', 'scipy', 'mpl_toolkits.mplot3d', 'queue', 'sympy', 'itertools', 'os', 'random', 'statistics', 'cmath', 'numpy', 'stat', 'datetime', 'pickle']\"}, {'start_idx': 421, 'end_idx': 426, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 38, 'action_unit_idx': None, 'start_pattern': 'import numpy as np\\nimport itertools\\n\\ndef generate_quadratic_combinations(x, y, z, N):'}]"
        ],
        [
         "2",
         "4501b779-18f4-4433-91a5-e78bed1f599a",
         "9d7383f6-e278-4fb9-aeb2-3620cc1b13b7",
         "31002fcf-8750-4615-9cdd-28206aad0636",
         "2",
         null,
         "direct_result",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "35",
         "35",
         "high",
         "False",
         "85",
         "85",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "[]",
         "False",
         "b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3",
         "2025-09-15 21:20:46.883193",
         "85",
         "match",
         "match",
         "The agent encountered an environmental restriction when attempting to import a disallowed module. Specifically, execution failed with: <RANGE>Code execution failed at line 'import heapq' due to: InterpreterError: Import of heapq is not allowed. Authorized imports are: </RANGE> T0B34. This is an environmental barrier preventing access to a tool (heapq) necessary for the chosen implementation approach, fitting the rubric's criteria.",
         "[{'start_idx': 278, 'end_idx': 283, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 34, 'action_unit_idx': None, 'start_pattern': None}]"
        ],
        [
         "3",
         "5b5f4408-422e-4a05-a0d4-0355ec8a1292",
         "9ebb1c86-9296-47ec-9386-8d4897ae28ba",
         "31002fcf-8750-4615-9cdd-28206aad0636",
         "2",
         null,
         "direct_result",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "15",
         "15",
         "high",
         "False",
         "58",
         "58",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "['15.1']",
         "True",
         "0d5487f6-f4da-4d09-8065-ffb0b42f5a2c",
         "2025-09-15 21:20:46.883170",
         "58",
         "match",
         "match",
         "The agent encountered environmental/tooling barriers during the run. First, the web_search tool was rate-limited, preventing access to search results at the time of use T0B7. Later, the python_interpreter environment did not support the matrix multiplication operator, causing a NotImplementedError during execution T0B39. These issues reflect barriers in the agent scaffold/tools that impeded proper tool access and typical Python operations.",
         "[{'start_idx': 169, 'end_idx': 173, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 7, 'action_unit_idx': None, 'start_pattern': 'Error:\\nCode execution failed at line \\'h_bar_search = web_search(\"reduced Planck constant value in Js\")\\' due to: DuckDuckGoSearchException: https://lite.duckduckgo.com/lite/ 202 Ratelimit'}, {'start_idx': 316, 'end_idx': 321, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 39, 'action_unit_idx': None, 'start_pattern': \"Error:\\nCode execution failed at line 'psi_final = crank_nicolson(sigma, kappa, T, nstep, N, L)' due to: NotImplementedError: Binary operation MatMult is not implemented.\"}]"
        ],
        [
         "4",
         "d638ca0e-49b9-4959-8c41-be41bba1e714",
         "2223fd62-676e-46af-867e-6f19d7f5df10",
         "31002fcf-8750-4615-9cdd-28206aad0636",
         "2",
         null,
         "direct_result",
         "scicode",
         "openai/claude-3-7-sonnet-20250219_high",
         "31",
         "31",
         "high",
         "False",
         "84",
         "84",
         "0",
         "scicode_scicode_tool_calling_agent_claude37sonnet20250219_high_1753770104_UPLOAD.zip",
         "62",
         "3",
         "['74', '25', '30']",
         "['31.1']",
         "True",
         "bc0819d1-388b-44f9-bc7f-6b840e95eae2",
         "2025-09-15 21:20:46.883188",
         "84",
         "match",
         "match",
         "The run encountered clear environmental barriers with the tools. The web_search tool was rate limited, preventing access despite a correct call, as shown by the DuckDuckGoSearchException and Ratelimit message T0B35. Additionally, the python_interpreter environment did not support the matrix multiplication operator '@', causing a NotImplementedError when attempting a standard operation for the task T0B38. These are environmental barriers that impeded proper tool access and expected operations, fitting the rubric's criteria.",
         "[{'start_idx': 209, 'end_idx': 214, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 35, 'action_unit_idx': None, 'start_pattern': 'Code execution failed at line \\'search_result = web_search(\"matrix whitening transformation covariance identity\")\\' due to: DuckDuckGoSearchException: https://html.duckduckgo.com/html 202 Ratelimit'}, {'start_idx': 401, 'end_idx': 406, 'agent_run_idx': None, 'transcript_idx': 0, 'block_idx': 38, 'action_unit_idx': None, 'start_pattern': \"Code execution failed at line 'cov_matrix = X_centered @ X_centered.T / X.shape[1]' due to: NotImplementedError: Binary operation MatMult is not implemented.\"}]"
        ]
       ],
       "shape": {
        "columns": 28,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>agent_run_id</th>\n",
       "      <th>rubric_id</th>\n",
       "      <th>rubric_version</th>\n",
       "      <th>value</th>\n",
       "      <th>result_type</th>\n",
       "      <th>benchmark_id</th>\n",
       "      <th>model</th>\n",
       "      <th>task_id</th>\n",
       "      <th>weave_task_id</th>\n",
       "      <th>...</th>\n",
       "      <th>eval_successful_tasks</th>\n",
       "      <th>eval_successful_subtasks</th>\n",
       "      <th>eval_has_successful_subtasks</th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>transcript_created_at</th>\n",
       "      <th>transcript_message_count</th>\n",
       "      <th>label</th>\n",
       "      <th>output_label</th>\n",
       "      <th>output_explanation.text</th>\n",
       "      <th>output_explanation.citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4b3c7a80-4033-4ea1-8da8-70eeb1769d02</td>\n",
       "      <td>c99750eb-391c-4416-af0e-37e1d88c3249</td>\n",
       "      <td>31002fcf-8750-4615-9cdd-28206aad0636</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>direct_result</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>1bf5f9a9-c7dd-4b64-b9c1-8331684187cb</td>\n",
       "      <td>2025-09-15 21:20:46.883184</td>\n",
       "      <td>85</td>\n",
       "      <td>match</td>\n",
       "      <td>match</td>\n",
       "      <td>The agent encountered an environmental barrier...</td>\n",
       "      <td>[{'start_idx': 175, 'end_idx': 179, 'agent_run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d83409ad-a78b-473d-9c0a-96188bcc3fd1</td>\n",
       "      <td>193fa9e6-f306-4884-aacc-f8b46b451af9</td>\n",
       "      <td>31002fcf-8750-4615-9cdd-28206aad0636</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>direct_result</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>['74', '36']</td>\n",
       "      <td>['35.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>3108978d-b4db-4632-9a95-c93ddd3c2f69</td>\n",
       "      <td>2025-09-15 21:20:37.011008</td>\n",
       "      <td>88</td>\n",
       "      <td>no match</td>\n",
       "      <td>no match</td>\n",
       "      <td>The agent did encounter an environmental restr...</td>\n",
       "      <td>[{'start_idx': 208, 'end_idx': 213, 'agent_run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4501b779-18f4-4433-91a5-e78bed1f599a</td>\n",
       "      <td>9d7383f6-e278-4fb9-aeb2-3620cc1b13b7</td>\n",
       "      <td>31002fcf-8750-4615-9cdd-28206aad0636</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>direct_result</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3</td>\n",
       "      <td>2025-09-15 21:20:46.883193</td>\n",
       "      <td>85</td>\n",
       "      <td>match</td>\n",
       "      <td>match</td>\n",
       "      <td>The agent encountered an environmental restric...</td>\n",
       "      <td>[{'start_idx': 278, 'end_idx': 283, 'agent_run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b5f4408-422e-4a05-a0d4-0355ec8a1292</td>\n",
       "      <td>9ebb1c86-9296-47ec-9386-8d4897ae28ba</td>\n",
       "      <td>31002fcf-8750-4615-9cdd-28206aad0636</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>direct_result</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>['15.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>0d5487f6-f4da-4d09-8065-ffb0b42f5a2c</td>\n",
       "      <td>2025-09-15 21:20:46.883170</td>\n",
       "      <td>58</td>\n",
       "      <td>match</td>\n",
       "      <td>match</td>\n",
       "      <td>The agent encountered environmental/tooling ba...</td>\n",
       "      <td>[{'start_idx': 169, 'end_idx': 173, 'agent_run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d638ca0e-49b9-4959-8c41-be41bba1e714</td>\n",
       "      <td>2223fd62-676e-46af-867e-6f19d7f5df10</td>\n",
       "      <td>31002fcf-8750-4615-9cdd-28206aad0636</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>direct_result</td>\n",
       "      <td>scicode</td>\n",
       "      <td>openai/claude-3-7-sonnet-20250219_high</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>['74', '25', '30']</td>\n",
       "      <td>['31.1']</td>\n",
       "      <td>True</td>\n",
       "      <td>bc0819d1-388b-44f9-bc7f-6b840e95eae2</td>\n",
       "      <td>2025-09-15 21:20:46.883188</td>\n",
       "      <td>84</td>\n",
       "      <td>match</td>\n",
       "      <td>match</td>\n",
       "      <td>The run encountered clear environmental barrie...</td>\n",
       "      <td>[{'start_idx': 209, 'end_idx': 214, 'agent_run...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                          agent_run_id  \\\n",
       "0  4b3c7a80-4033-4ea1-8da8-70eeb1769d02  c99750eb-391c-4416-af0e-37e1d88c3249   \n",
       "1  d83409ad-a78b-473d-9c0a-96188bcc3fd1  193fa9e6-f306-4884-aacc-f8b46b451af9   \n",
       "2  4501b779-18f4-4433-91a5-e78bed1f599a  9d7383f6-e278-4fb9-aeb2-3620cc1b13b7   \n",
       "3  5b5f4408-422e-4a05-a0d4-0355ec8a1292  9ebb1c86-9296-47ec-9386-8d4897ae28ba   \n",
       "4  d638ca0e-49b9-4959-8c41-be41bba1e714  2223fd62-676e-46af-867e-6f19d7f5df10   \n",
       "\n",
       "                              rubric_id  rubric_version value    result_type  \\\n",
       "0  31002fcf-8750-4615-9cdd-28206aad0636               2  None  direct_result   \n",
       "1  31002fcf-8750-4615-9cdd-28206aad0636               2  None  direct_result   \n",
       "2  31002fcf-8750-4615-9cdd-28206aad0636               2  None  direct_result   \n",
       "3  31002fcf-8750-4615-9cdd-28206aad0636               2  None  direct_result   \n",
       "4  31002fcf-8750-4615-9cdd-28206aad0636               2  None  direct_result   \n",
       "\n",
       "  benchmark_id                                   model task_id weave_task_id  \\\n",
       "0      scicode  openai/claude-3-7-sonnet-20250219_high      27            27   \n",
       "1      scicode       openai/claude-3-7-sonnet-20250219      35            35   \n",
       "2      scicode  openai/claude-3-7-sonnet-20250219_high      35            35   \n",
       "3      scicode  openai/claude-3-7-sonnet-20250219_high      15            15   \n",
       "4      scicode  openai/claude-3-7-sonnet-20250219_high      31            31   \n",
       "\n",
       "   ... eval_successful_tasks  eval_successful_subtasks  \\\n",
       "0  ...    ['74', '25', '30']                        []   \n",
       "1  ...          ['74', '36']                  ['35.1']   \n",
       "2  ...    ['74', '25', '30']                        []   \n",
       "3  ...    ['74', '25', '30']                  ['15.1']   \n",
       "4  ...    ['74', '25', '30']                  ['31.1']   \n",
       "\n",
       "   eval_has_successful_subtasks                         transcript_id  \\\n",
       "0                         False  1bf5f9a9-c7dd-4b64-b9c1-8331684187cb   \n",
       "1                          True  3108978d-b4db-4632-9a95-c93ddd3c2f69   \n",
       "2                         False  b9deaa65-5a5e-48ce-b7a7-a1124dfda0c3   \n",
       "3                          True  0d5487f6-f4da-4d09-8065-ffb0b42f5a2c   \n",
       "4                          True  bc0819d1-388b-44f9-bc7f-6b840e95eae2   \n",
       "\n",
       "       transcript_created_at transcript_message_count     label  output_label  \\\n",
       "0 2025-09-15 21:20:46.883184                       85     match         match   \n",
       "1 2025-09-15 21:20:37.011008                       88  no match      no match   \n",
       "2 2025-09-15 21:20:46.883193                       85     match         match   \n",
       "3 2025-09-15 21:20:46.883170                       58     match         match   \n",
       "4 2025-09-15 21:20:46.883188                       84     match         match   \n",
       "\n",
       "                             output_explanation.text  \\\n",
       "0  The agent encountered an environmental barrier...   \n",
       "1  The agent did encounter an environmental restr...   \n",
       "2  The agent encountered an environmental restric...   \n",
       "3  The agent encountered environmental/tooling ba...   \n",
       "4  The run encountered clear environmental barrie...   \n",
       "\n",
       "                        output_explanation.citations  \n",
       "0  [{'start_idx': 175, 'end_idx': 179, 'agent_run...  \n",
       "1  [{'start_idx': 208, 'end_idx': 213, 'agent_run...  \n",
       "2  [{'start_idx': 278, 'end_idx': 283, 'agent_run...  \n",
       "3  [{'start_idx': 169, 'end_idx': 173, 'agent_run...  \n",
       "4  [{'start_idx': 209, 'end_idx': 214, 'agent_run...  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out rows where output['label'] == 'no match' and expand output keys into columns\n",
    "def expand_output_column(df, output_col='output'):\n",
    "    \"\"\"\n",
    "    Filter out 'no match' labels and expand output dictionary keys into separate columns.\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original\n",
    "    expanded_df = df.copy()\n",
    "    \n",
    "    # Extract label for filtering\n",
    "    expanded_df['label'] = expanded_df[output_col].apply(\n",
    "        lambda x: x.get('label') if isinstance(x, dict) else None\n",
    "    )\n",
    "    \n",
    "    # Expand all keys from the output dictionary\n",
    "    output_expanded = pd.json_normalize(expanded_df[output_col])\n",
    "    \n",
    "    # Add prefix to avoid column name conflicts\n",
    "    output_expanded.columns = [f'output_{col}' for col in output_expanded.columns]\n",
    "    \n",
    "    # Reset indices to align properly\n",
    "    filtered_df_reset = expanded_df.reset_index(drop=True)\n",
    "    output_expanded_reset = output_expanded.reset_index(drop=True)\n",
    "    \n",
    "    # Concatenate the original columns (minus output) with expanded columns\n",
    "    final_df = pd.concat([\n",
    "        filtered_df_reset.drop(columns=[output_col]),\n",
    "        output_expanded_reset\n",
    "    ], axis=1)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Apply the function\n",
    "expanded_df = expand_output_column(merged_df)\n",
    "\n",
    "print(f\"Original shape: {merged_df.shape}\")\n",
    "print(f\"Filtered & expanded shape: {expanded_df.shape}\")\n",
    "print(f\"Rows with 'no match' removed: {merged_df.shape[0] - expanded_df.shape[0]}\")\n",
    "print(f\"\\nNew columns from output expansion:\")\n",
    "new_cols = [col for col in expanded_df.columns if col.startswith('output_')]\n",
    "print(new_cols)\n",
    "\n",
    "# Show the first few rows\n",
    "expanded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c70d4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep columns benchmark, model, task_id, agent_run_id, value, citation, eval_is_successful, docent_message_count\n",
    "expanded_df = expanded_df[['benchmark_id', 'model', 'task_id', 'agent_run_id', 'eval_has_successful_subtasks', 'eval_is_successful', 'label', 'output_explanation.text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "753837fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df.to_csv(\"../results/rubrics/scicode_environmentalbarrier.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04f68672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dc/2_03ytv916s79g_kt7ch3ck00000gn/T/ipykernel_9086/176421393.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = expanded_df.groupby(['model', 'label']).apply(lambda x: x.sample(n=3, random_state=42) if len(x) > 4 else x)\n"
     ]
    }
   ],
   "source": [
    "# randomly sample 5 rows from the merged_df, stratified by model\n",
    "sampled_df = expanded_df.groupby(['model', 'label']).apply(lambda x: x.sample(n=3, random_state=42) if len(x) > 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac825bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.to_csv(\"../results/validations/corebench_verification.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ae7040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cond_prob_success",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "187f38ad-af17-481b-a722-00c16105c46b",
       "rows": [
        [
         "0",
         "match",
         "0.48329621380846327"
        ],
        [
         "1",
         "no match",
         "0.313953488372093"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cond_prob_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>match</td>\n",
       "      <td>0.483296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no match</td>\n",
       "      <td>0.313953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  cond_prob_success\n",
       "0     match           0.483296\n",
       "1  no match           0.313953"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute conditional probability of eval_is_successful given label\n",
    "cond_probs = expanded_df.groupby(['label'])['eval_has_successful_subtasks'].mean().reset_index()\n",
    "cond_probs = cond_probs.rename(columns={'eval_has_successful_subtasks': 'cond_prob_success'})\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "40026086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_is_successful",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "label",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f8ef61b0-72df-489f-b2be-6173f01761e7",
       "rows": [
        [
         "0",
         "False",
         "0.43824027072758037"
        ],
        [
         "1",
         "True",
         "0.28"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_is_successful</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.43824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.28000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_is_successful    label\n",
       "0               False  0.43824\n",
       "1                True  0.28000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert label to boolean with match = True and no match = False\n",
    "expanded_df['label'] = expanded_df['label'].map({'match': True, 'no match': False})\n",
    "expanded_df['label'] = expanded_df['label'].astype(bool)\n",
    "\n",
    "# compute conditional probability of label given eval_is_successful\n",
    "expanded_df['eval_is_successful'] = expanded_df['eval_is_successful'].astype(bool)\n",
    "cond_probs = expanded_df.groupby(['eval_is_successful'])['label'].mean().reset_index()\n",
    "cond_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e1c763e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cond_prob_success",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "71fd6204-660e-4b28-b290-930c1cfd8945",
       "rows": [
        [
         "0",
         "match",
         "0.7563025210084033"
        ],
        [
         "1",
         "no match",
         "0.5155038759689923"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>cond_prob_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>match</td>\n",
       "      <td>0.756303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no match</td>\n",
       "      <td>0.515504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  cond_prob_success\n",
       "0     match           0.756303\n",
       "1  no match           0.515504"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute conditional probability of eval_is_successful given label\n",
    "cond_probs = expanded_df.groupby(['label'])['eval_answer'].mean().reset_index()\n",
    "cond_probs = cond_probs.rename(columns={'eval_answer': 'cond_prob_success'})\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cbf2bc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "eval_answer",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "label",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "21f55fee-04cd-4221-ad14-c38a44a62aa8",
       "rows": [
        [
         "0",
         "0.0",
         "0.5641025641025641"
        ],
        [
         "1",
         "1.0",
         "0.022935779816513763"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_answer</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eval_answer     label\n",
       "0          0.0  0.564103\n",
       "1          1.0  0.022936"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter to eval_score > 0\n",
    "# expanded_df = expanded_df[expanded_df['eval_score'] > 0]\n",
    "\n",
    "# Make a flag for is_successful if eval_score > 0.3\n",
    "expanded_df['eval_is_successful'] = expanded_df['eval_score'] > 0.75\n",
    "\n",
    "# convert label to boolean with match = True and no match = False\n",
    "expanded_df['label'] = expanded_df['label'].map({'match': True, 'no match': False})\n",
    "expanded_df['label'] = expanded_df['label'].astype(bool)\n",
    "\n",
    "# compute conditional probability of label given eval_is_successful\n",
    "cond_probs = expanded_df.groupby(['eval_answer'])['label'].mean().reset_index()\n",
    "cond_probs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
